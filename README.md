# :boom: Awesome-Vision-Language-Models (VLMs)-in-Autonomous-Driving (AD)-and-Intelligent-Transportation-Systems (ITS)
This repository collects research papers on large **Vision Language Models in Autonomous Driving and Intelligent Transportation Systems**. The repository will be continuously updated to track the latest updates. 
 
If there are any omissions or suggestions, you're warmly welcome to reach out to us (xingcheng.zhou@tum.de or mingyu.liu@tum.de). The repo is maintained by [TUM-AIR](https://www.ce.cit.tum.de/air/home/).

<p align="center">
<img src="Assets/figure1.png" width="330" height="330"/>
</p>

## :fire: :fire: Citate our Paper!
Please visit [Vision Language Models in Autonomous Driving and Intelligent Transportation Systems](https://arxiv.org/pdf/2310.14414.pdf) for more details and comprehensive information. If you find our repo and paper helpful, please cite it as following.

```BibTeX
@misc{zhou2023vision,
      title={Vision Language Models in Autonomous Driving and Intelligent Transportation Systems}, 
      author={Xingcheng Zhou and Mingyu Liu and Bare Luka Zagar and Ekim Yurtsever and Alois C. Knoll},
      year={2023},
      eprint={2310.14414},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## :fire: :fire: Introduction
The applications of **Vision-Language Models (VLMs)** in the fields of **Autonomous Driving (AD)** and **Intelligent Transportation Systems (ITS)** have attracted widespread attention due to their outstanding performance and the ability to leverage **Large Language Models (LLMs)**. By integrating
language data, the vehicles, and transportation systems are able to deeply understand real-world environments, improving driving safety and efficiency

<p align="center">
<img src="Assets/figure2.png"/>
</p>

## :fire: :fire: Large VLMs in Autonomous Driving

### :star: Perception and Understanding
| Method                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Year | Task                                                | Code Link                                                        |                                               
|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|-----------------------------------------------------|------------------------------------------------------------------| 
| [The Traffic Scene Understanding and Prediction Based on Image Captioning](https://ieeexplore.ieee.org/document/9306804)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 2020 | Image Captioning                                    |                                                                  | 
| [VLPD: Context-Aware Pedestrian Detection via Vision-Language Semantic Self-Supervision](https://arxiv.org/pdf/2304.03135.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 2023 | Pedestrian Detection                                | [Github](https://github.com/lmy98129/VLPD)                       | 
| [Unsupervised Multi-view Pedestrian Detection](https://arxiv.org/pdf/2305.12457.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 2023 | Pedestrian Detection                                |                                                                  | 
| [Language-Guided 3D Object Detection in Point Cloud for Autonomous Driving](https://arxiv.org/pdf/2305.15765.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 2023 | Single Object Referring                             |                                                                  | 
| [Referring Multi-Object Tracking](https://arxiv.org/pdf/2303.03366.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 2023 | Multiple Objects Referring and Tracking             | [Github](https://github.com/wudongming97/rmot)                   | 
| [Language Prompt for Autonomous Driving](https://arxiv.org/pdf/2309.04379v1.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 2023 | Multiple Objects Referring and Tracking             | [Github](https://github.com/wudongming97/prompt4driving)         | 
| [OpenScene: 3D Scene Understanding with Open Vocabularies](https://arxiv.org/pdf/2211.15654.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 2023 | Open-Voc 3D Semantic Segmentation                   | [Github](https://github.com/pengsongyou/openscene)               |
| [CLIP2Scene: Towards Label-efficient 3D Scene Understanding by CLIP](https://arxiv.org/pdf/2301.04926.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 2023 | Open-Voc 3D Semantic Segmentation                   | [Github](https://github.com/runnanchen/CLIP2Scene)               | 
| [Unsupervised 3D Perception with 2D Vision-Language Distillation for Autonomous Driving](https://openaccess.thecvf.com/content/ICCV2023/papers/Najibi_Unsupervised_3D_Perception_with_2D_Vision-Language_Distillation_for_Autonomous_Driving_ICCV_2023_paper.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                            | 2023 | Open-Voc 3D Object Detection and Tracking           |                                                                  | 
| [Zelda: Video Analytics using Vision-Language Models](https://arxiv.org/pdf/2305.03785.pdf#:~:text=We%20present%20Zelda%3A%20a%20video,and%20identify%20low%2Dquality%20frames.)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | 2023 | Language-guided Video Retrieval                     |                                                                  | 
| [NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for Autonomous Driving Scenario](https://arxiv.org/pdf/2305.14836.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 2023 | Visual Question Answering                           | [Github](https://github.com/qiantianwen/NuScenes-QA)             | 
| [Talk2BEV: Language-Enhanced Bird's Eye View (BEV) Maps](https://arxiv.org/abs/2310.02251)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | 2023 | Visual Spatiel Reasoning, Open-loop Decision making | [Github](https://github.com/llmbev/talk2bev)                     | 
| [Semantic Anomaly Detection with Large Language Models](https://arxiv.org/pdf/2305.11307.pdf)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 2023 | Semantic Anomaly Detection                          |                                                                  |

### :star: Navigation and Planning
| Method                                                                                                                                                                       | Year | Task                                                     | Code Link                                              |                                               
|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|----------------------------------------------------------|--------------------------------------------------------| 
| [Talk to the vehicle: Language conditioned autonomous navigation of self driving car](https://ieeexplore.ieee.org/document/8967929)                                          | 2019 | Language-Guided Navigation                               |                                                        | 
| [Ground then Navigate: Language-guided Navigation in Dynamic Scenes](https://arxiv.org/abs/2209.11972)                                                                       | 2022 | Language-Guided Navigation                               |                                                        |
| [ALT-Pilot: Autonomous navigation with Language augmented Topometric maps](https://arxiv.org/pdf/2310.02324.pdf)                                                             | 2023 | Vision-Language Localization, Language-Guided Navigation | [Page](https://navigate-anywhere.github.io/ALT-Pilot/) |
| [GPT-Driver: Learning to Drive with GPT](https://arxiv.org/pdf/2310.01415.pdf)                                                                                               | 2023 | Motion Planing                                           | [Github](https://github.com/PointsCoder/GPT-Driver)    |
| [Can you text what is happening? Integrating pre-trained language encoders into trajectory prediction models for autonomous driving](https://arxiv.org/pdf/2309.05282.pdf)   | 2023 | Trajectory Prediction                                    |                                                        |

### :star: Decision-Making and Control
| Method                                                                                                                                                                                                                                                                | Year | Task                                        | Code Link                                              |                                               
|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|---------------------------------------------|--------------------------------------------------------| 
| [Advisable Learning for Self-driving Vehicles by Internalizing Observation-to-Action Rules](https://openaccess.thecvf.com/content_CVPR_2020/papers/Kim_Advisable_Learning_for_Self-Driving_Vehicles_by_Internalizing_Observation-to-Action_Rules_CVPR_2020_paper.pdf) | 2020 | Open-loop Decision-Making                   |                                                        |
| [LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving](https://arxiv.org/pdf/2310.03026.pdf)                                                                                                                                                  | 2023 | Open-loop Decision-Making                   |                                                        |
| [Receive, Reason, and React: Drive as You Say with Large Language Models in Autonomous Vehicles](https://arxiv.org/pdf/2310.08034v1.pdf)                                                                                                                              | 2023 | Open-loop Decision-Making, Motion Planing   |                                                        |
| [Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving](https://arxiv.org/abs/2310.01957)                                                                                                                                         | 2023 | Open-loop Control, Visual Spatial Reasoning | [Github](https://github.com/wayveai/Driving-with-LLMs) |
| [DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models](https://arxiv.org/pdf/2309.16292.pdf)                                                                                                                                            | 2023 | Closed-loop Decision-Making                 |                                                        |
| [SurrealDriver: Designing Generative Driver Agent Simulation Framework in Urban Contexts based on Large Language Model](https://arxiv.org/pdf/2309.13193.pdf)                                                                                                         | 2023 | Closed-loop Decision-Making                 |                                                        |
| [Drive Like a Human: Rethinking Autonomous Driving with Large Language Models](https://arxiv.org/pdf/2307.07162.pdf)                                                                                                                                                  | 2023 | Closed-loop Decision-Making                 | [Github](https://github.com/PJLab-ADG/DriveLikeAHuman) |


### :star: End-to-End Autonomous Driving
| Method                                                                                                                                                             | Year | Task                                                | Code Link                                                                               |                                               
|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|-----------------------------------------------------|-----------------------------------------------------------------------------------------| 
| [DriveGPT4: Interpretable End-to-end Autonomous Driving via Large Language Model](https://arxiv.org/pdf/2310.01412.pdf)                                            | 2023 | Open-loop Control, Visual Question Answering        | []()                                                                                    |
| [ADAPT: Action-aware Driving Caption Transformer](https://arxiv.org/pdf/2302.00673.pdf)                                                                            | 2023 | Open-loop Decision-Making, Visual Spatial Reasoning | [Github](https://github.com/jxbbb/ADAPT#adapt-action-aware-driving-caption-transformer) |

### :star: Data Generation
| Method                                                                                                                                                                                                                              | Year | Task                         | Code Link                                                     |                                               
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------|------------------------------|---------------------------------------------------------------| 
| [DriveGAN: Towards a Controllable High-Quality Neural Simulation](https://arxiv.org/pdf/2104.15060.pdf)                                                                                                                             | 2021 | Conditional Video Generation | [Page](https://research.nvidia.com/labs/toronto-ai/DriveGAN/) |
| [GAIA-1: A Generative World Model for Autonomous Driving](https://arxiv.org/pdf/2309.17080.pdf)                                                                                                                                     | 2023 | Conditional Video Generation | [Page](https://wayve.ai/thinking/introducing-gaia1/)          |
| [DriveDreamer: Towards Real-world-driven World Models for Autonomous Driving](https://arxiv.org/pdf/2309.09777.pdf)                                                                                                                 | 2023 | Conditional Video Generation | [Github](https://github.com/JeffWang987/DriveDreamer)         |
| [DrivingDiffusion: Layout-Guided multi-view driving scene video generation with latent diffusion model](https://arxiv.org/pdf/2310.07771.pdf)                                                                                       | 2023 | Conditional Image Generation | [Github](https://github.com/shalfun/DrivingDiffusion)         |
| [BEVControl: Accurately Controlling Street-view Elements with Multi-perspective Consistency via BEV Sketch Layout](https://arxiv.org/pdf/2308.01661.pdf)                                                                            | 2023 | Conditional Image Generation |                                                               |
